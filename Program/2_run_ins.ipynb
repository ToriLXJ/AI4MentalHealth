{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2581c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. Training XGBoost ===\n",
      "Start hyperparameter search...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "=== RandomizedSearchCV ===\n",
      "Best CV Score: -4.409187337264696\n",
      "Best Params: {'xgb__subsample': 0.7, 'xgb__reg_lambda': 1, 'xgb__reg_alpha': 2, 'xgb__n_estimators': 600, 'xgb__min_child_weight': 15, 'xgb__max_depth': 2, 'xgb__learning_rate': 0.01, 'xgb__gamma': 0.1, 'xgb__colsample_bytree': 0.4, 'xgb__colsample_bylevel': 0.8}\n",
      "[0]\ttrain-rmse:5.22480\teval-rmse:5.50248\n",
      "[50]\ttrain-rmse:4.86647\teval-rmse:5.01051\n",
      "[100]\ttrain-rmse:4.63576\teval-rmse:4.69617\n",
      "[150]\ttrain-rmse:4.48373\teval-rmse:4.49937\n",
      "[200]\ttrain-rmse:4.37943\teval-rmse:4.38591\n",
      "[250]\ttrain-rmse:4.30588\teval-rmse:4.32055\n",
      "[300]\ttrain-rmse:4.24386\teval-rmse:4.27301\n",
      "[350]\ttrain-rmse:4.19632\teval-rmse:4.24728\n",
      "[400]\ttrain-rmse:4.15280\teval-rmse:4.22988\n",
      "[450]\ttrain-rmse:4.11562\teval-rmse:4.22128\n",
      "[500]\ttrain-rmse:4.08017\teval-rmse:4.20816\n",
      "[550]\ttrain-rmse:4.04910\teval-rmse:4.20182\n",
      "[559]\ttrain-rmse:4.04394\teval-rmse:4.19970\n",
      "XGB Test R2: 0.2678\n",
      "\n",
      "=== 2. Training LightGBM ===\n",
      "Start optimized search on 753 samples with 36 features...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "\n",
      "=== RandomizedSearchCV Results ===\n",
      "Best CV Score (RMSE): 4.4242\n",
      "Best Params: {'lgbm__subsample_freq': 1, 'lgbm__subsample': 0.8, 'lgbm__reg_lambda': 1, 'lgbm__reg_alpha': 10, 'lgbm__objective': 'regression', 'lgbm__num_leaves': 7, 'lgbm__n_estimators': 800, 'lgbm__min_child_samples': 15, 'lgbm__max_depth': -1, 'lgbm__learning_rate': 0.005, 'lgbm__colsample_bytree': 0.7, 'lgbm__boosting_type': 'gbdt'}\n",
      "\n",
      "Training final model with Early Stopping (Patience=100)...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\ttraining's rmse: 4.42732\ttraining's l2: 19.6012\tvalid_1's rmse: 4.55026\tvalid_1's l2: 20.7048\n",
      "[400]\ttraining's rmse: 4.09957\ttraining's l2: 16.8064\tvalid_1's rmse: 4.30748\tvalid_1's l2: 18.5544\n",
      "[600]\ttraining's rmse: 3.90523\ttraining's l2: 15.2508\tvalid_1's rmse: 4.25031\tvalid_1's l2: 18.0651\n",
      "[800]\ttraining's rmse: 3.75603\ttraining's l2: 14.1078\tvalid_1's rmse: 4.23456\tvalid_1's l2: 17.9315\n",
      "Early stopping, best iteration is:\n",
      "[779]\ttraining's rmse: 3.7703\ttraining's l2: 14.2151\tvalid_1's rmse: 4.23278\tvalid_1's l2: 17.9164\n",
      "LGBM Test R2: 0.2604\n",
      "\n",
      "=== 3. Training CatBoost ===\n",
      "Start CatBoost hyperparameter search...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "=== CatBoost RandomizedSearchCV ===\n",
      "Best CV Score: -4.375130613086914\n",
      "Best Params: {'cat__subsample': 0.8, 'cat__rsm': 0.9, 'cat__min_data_in_leaf': 5, 'cat__learning_rate': 0.01, 'cat__l2_leaf_reg': 5, 'cat__iterations': 800, 'cat__depth': 4}\n",
      "\n",
      "Training final CatBoost model...\n",
      "0:\tlearn: 5.2182831\ttest: 5.4908885\tbest: 5.4908885 (0)\ttotal: 1.68ms\tremaining: 3.35s\n",
      "100:\tlearn: 4.5906960\ttest: 4.7080721\tbest: 4.7080721 (100)\ttotal: 177ms\tremaining: 3.34s\n",
      "200:\tlearn: 4.3191968\ttest: 4.3768265\tbest: 4.3768265 (200)\ttotal: 312ms\tremaining: 2.79s\n",
      "300:\tlearn: 4.1707269\ttest: 4.2469016\tbest: 4.2469016 (300)\ttotal: 469ms\tremaining: 2.64s\n",
      "400:\tlearn: 4.0581826\ttest: 4.1973693\tbest: 4.1973693 (400)\ttotal: 643ms\tremaining: 2.56s\n",
      "500:\tlearn: 3.9698442\ttest: 4.1675754\tbest: 4.1672069 (496)\ttotal: 841ms\tremaining: 2.52s\n",
      "600:\tlearn: 3.8815703\ttest: 4.1556213\tbest: 4.1536032 (592)\ttotal: 999ms\tremaining: 2.33s\n",
      "700:\tlearn: 3.8015532\ttest: 4.1341204\tbest: 4.1328713 (699)\ttotal: 1.16s\tremaining: 2.16s\n",
      "800:\tlearn: 3.7308713\ttest: 4.1074218\tbest: 4.1073472 (796)\ttotal: 1.37s\tremaining: 2.05s\n",
      "900:\tlearn: 3.6631466\ttest: 4.0837523\tbest: 4.0828335 (895)\ttotal: 1.51s\tremaining: 1.84s\n",
      "1000:\tlearn: 3.5878950\ttest: 4.0798545\tbest: 4.0754192 (970)\ttotal: 1.67s\tremaining: 1.67s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 4.075419152\n",
      "bestIteration = 970\n",
      "\n",
      "Shrink model to first 971 iterations.\n",
      "CatBoost Test R2: 0.2764\n",
      "\n",
      "=== 4. Training RandomForest ===\n",
      "Start Random Forest search on 640 samples...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best RF Params: {'rf__n_estimators': 300, 'rf__min_samples_split': 20, 'rf__min_samples_leaf': 5, 'rf__max_features': 0.4, 'rf__max_depth': 16, 'rf__bootstrap': True}\n",
      "RF Test R2: 0.2676\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from ML_xgboost import train_xgboost_model\n",
    "from ML_lightgbm import train_lightgbm_model\n",
    "from ML_catboost import train_catboost_model\n",
    "from ML_randomforest import train_randomforest_model \n",
    "\n",
    "df_model = pd.read_csv(\"D:/Research-SJTUH/UniversityData/UniData/INS_prediction/Input/df_model_ins.csv\")\n",
    "\n",
    "selected_vars = [\n",
    "    \"somatic_y1\", \"BMI_T1_cat\", \"sleep_dura_T1_cat\", \"sleep_quali_T1\", \"insomnia_y1\",\n",
    "    \"life_satis_y1\", \"ms_ses_y1\", \"per_stress_y1\", \"ms_stress_y1\", \"depression_y1\", \"anxiety_y1\",\n",
    "    \"ace\", \"loneliness_y1\", \"support_y1\", \"gender_T1\", \"age_T1\", \"residence\", \"income\", \n",
    "    \"pocket_mon_T1\", \"income_ineqCity_y1\", \"sss_now\", \"marrige_par_bin\", \"edu_pa\",\n",
    "    \"eat_unctl_y1\", \"eat_emot_y1\", \"food_sweetdrink_T1\", \"food_takeout_T1\",\n",
    "    \"IPAQ_T1_1_bin\", \"IPAQ_T1_3_bin\", \"IPAQ_T1_5_bin\", \"screenT_weekday_T1\", \"screenT_weekend_T1\",\n",
    "    \"psmu_y1\", \"media_BadMood_T1\", \"media_GoodMood_T1\", \"edu_self\"\n",
    "]\n",
    "\n",
    "y_col = \"insomnia_y2\"\n",
    "y = pd.to_numeric(df_model[y_col], errors=\"coerce\")\n",
    "X = df_model[selected_vars].copy()\n",
    "\n",
    "RANDOM_STATE = 1234\n",
    "TEST_SIZE = 0.30\n",
    "VAL_SIZE = 0.15\n",
    "\n",
    "# === 1. Training XGBoost ===\n",
    "print(\"=== 1. Training XGBoost ===\")\n",
    "res_xgb = train_xgboost_model(X, y, selected_vars, RANDOM_STATE, TEST_SIZE, VAL_SIZE)\n",
    "print(f\"XGB Test R2: {res_xgb['test_r2']:.4f}\")\n",
    "\n",
    "# === 2. Training LightGBM ===\n",
    "print(\"\\n=== 2. Training LightGBM ===\")\n",
    "res_lgbm = train_lightgbm_model(X, y, selected_vars, RANDOM_STATE, TEST_SIZE, VAL_SIZE)\n",
    "print(f\"LGBM Test R2: {res_lgbm['test_r2']:.4f}\")\n",
    "\n",
    "# === 3. Training CatBoost ===\n",
    "print(\"\\n=== 3. Training CatBoost ===\")\n",
    "res_cat = train_catboost_model(X, y, selected_vars, RANDOM_STATE, TEST_SIZE, VAL_SIZE)\n",
    "print(f\"CatBoost Test R2: {res_cat['test_r2']:.4f}\")\n",
    "\n",
    "# === 4. Training Random Forest ===\n",
    "print(\"\\n=== 4. Training RandomForest ===\")\n",
    "res_rf = train_randomforest_model(X, y, selected_vars, RANDOM_STATE, TEST_SIZE, VAL_SIZE)\n",
    "print(f\"RF Test R2: {res_rf['test_r2']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c60503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The comparison of models had been saved in: plots/Performance_Comparison_5Models.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "models = ['RandomForest', 'XGBoost', 'LightGBM', 'CatBoost']\n",
    "\n",
    "# R2 Score: higher is better\n",
    "r2_scores = [\n",
    "    res_rf['test_r2'], \n",
    "    res_xgb['test_r2'], \n",
    "    res_lgbm['test_r2'], \n",
    "    res_cat['test_r2']\n",
    "]\n",
    "\n",
    "# RMSE Score: lower is better\n",
    "rmse_scores = [\n",
    "    res_rf['test_rmse'], \n",
    "    res_xgb['test_rmse'], \n",
    "    res_lgbm['test_rmse'], \n",
    "    res_cat['test_rmse']\n",
    "]\n",
    "\n",
    "# create DataFrame\n",
    "df_perf = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Test R2': r2_scores,\n",
    "    'Test RMSE': rmse_scores\n",
    "})\n",
    "\n",
    "# pltting settings\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Times New Roman',\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'font.size': 12\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8), dpi=400, tight_layout=True)\n",
    "\n",
    "sns.barplot(x='Model', y='Test R2', data=df_perf, ax=axes[0], palette=\"viridis\")\n",
    "axes[0].set_title(f'Test Set R² Comparison')\n",
    "axes[0].set_ylabel('R² Score')\n",
    "axes[0].tick_params(axis='x') # rotation=15\n",
    "\n",
    "for i in axes[0].containers:\n",
    "    axes[0].bar_label(i, fmt='%.4f', label_type='edge', padding=3)\n",
    "axes[0].margins(y=0.1)\n",
    "\n",
    "sns.barplot(x='Model', y='Test RMSE', data=df_perf, ax=axes[1], palette=\"magma\")\n",
    "axes[1].set_title(f'Test Set RMSE Comparison')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].tick_params(axis='x')\n",
    "\n",
    "for i in axes[1].containers:\n",
    "    axes[1].bar_label(i, fmt='%.4f', label_type='edge', padding=3)\n",
    "axes[1].margins(y=0.1)\n",
    "\n",
    "# plt.suptitle(f'Ensemble vs. Individual Model Performance for Insomnia Prediction', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "save_path = f\"plots/Performance_Comparison_5Models.png\"\n",
    "plt.savefig(save_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n The comparison of models had been saved in: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049e48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "All model performances had been saved in: output/Single_Model_Full_Performance.xlsx\n",
      "==================================================\n",
      "\n",
      "=== The comparison of model performance ===\n",
      "           Model     Dataset        R2      RMSE       MAE\n",
      "11      CatBoost        Test  0.276412  4.274304  3.318711\n",
      "9       CatBoost       Train  0.524324  3.607470  2.875133\n",
      "10      CatBoost  Validation  0.451936  4.075419  3.264157\n",
      "8       LightGBM        Test  0.260387  4.321375  3.383927\n",
      "6       LightGBM       Train  0.480425  3.770259  2.979080\n",
      "7       LightGBM  Validation  0.408795  4.232782  3.297552\n",
      "2   RandomForest        Test  0.267618  4.300198  3.350538\n",
      "0   RandomForest       Train  0.560353  3.468158  2.681885\n",
      "1   RandomForest  Validation  0.410938  4.225104  3.275081\n",
      "5        XGBoost        Test  0.267758  4.299785  3.373761\n",
      "3        XGBoost       Train  0.396606  4.063004  3.222202\n",
      "4        XGBoost  Validation  0.418531  4.197783  3.267958\n",
      "\n",
      " All performance comparison had been save in: plots/Performance_Comparison_5Models_Full_Comparison.png\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "results = {\n",
    "    'RandomForest': res_rf,\n",
    "    'XGBoost': res_xgb,\n",
    "    'LightGBM': res_lgbm,\n",
    "    'CatBoost': res_cat\n",
    "}\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for model_name, res in results.items():\n",
    "    # Train set metrics\n",
    "    data_list.append({\n",
    "        'Model': model_name,\n",
    "        'Dataset': 'Train',\n",
    "        'R2': res['train_r2'],\n",
    "        'RMSE': res['train_rmse'],\n",
    "        'MAE': res['train_mae']\n",
    "    })\n",
    "    \n",
    "    # Evalidation set metrics\n",
    "    data_list.append({\n",
    "        'Model': model_name,\n",
    "        'Dataset': 'Validation',\n",
    "        'R2': res['val_r2'],\n",
    "        'RMSE': res['val_rmse'],\n",
    "        'MAE': res['val_mae']\n",
    "    })\n",
    "    \n",
    "    # Test set metrics\n",
    "    data_list.append({\n",
    "        'Model': model_name,\n",
    "        'Dataset': 'Test',\n",
    "        'R2': res['test_r2'],\n",
    "        'RMSE': res['test_rmse'],\n",
    "        'MAE': res['test_mae']\n",
    "    })\n",
    "\n",
    "# DataFrame\n",
    "df_final_perf = pd.DataFrame(data_list)\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True) \n",
    "\n",
    "excel_save_path = f\"output/Single_Model_Full_Performance.xlsx\"\n",
    "df_final_perf = df_final_perf.sort_values(by=['Model', 'Dataset'])\n",
    "\n",
    "df_final_perf.to_excel(excel_save_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"All model performances had been saved in: {excel_save_path}\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n=== The comparison of model performance ===\")\n",
    "print(df_final_perf)\n",
    "\n",
    "# === Plot ===\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'Times New Roman',\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 14,\n",
    "    'ytick.labelsize': 14,\n",
    "    'legend.fontsize': 14,\n",
    "    'font.size': 12\n",
    "})\n",
    "\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7), dpi=400, tight_layout=True)\n",
    "\n",
    "# --- 1. R² Score (Higher is better) ---\n",
    "sns.barplot(\n",
    "    x='Model', \n",
    "    y='R2', \n",
    "    hue='Dataset', \n",
    "    data=df_final_perf, \n",
    "    ax=axes[0], \n",
    "    palette=\"viridis\"\n",
    ")\n",
    "axes[0].set_title('R² Performance Comparison')\n",
    "axes[0].set_ylabel('R² Score')\n",
    "axes[0].tick_params(axis='x')\n",
    "axes[0].legend(title='Dataset')\n",
    "\n",
    "# --- 2. RMSE (Lower is better) ---\n",
    "sns.barplot(\n",
    "    x='Model', \n",
    "    y='RMSE', \n",
    "    hue='Dataset', \n",
    "    data=df_final_perf, \n",
    "    ax=axes[1], \n",
    "    palette=\"magma\"\n",
    ")\n",
    "axes[1].set_ylim(0, 5)\n",
    "axes[1].set_title('RMSE Performance Comparison')\n",
    "axes[1].set_ylabel('RMSE')\n",
    "axes[1].tick_params(axis='x')\n",
    "axes[1].legend(title='Dataset')\n",
    "\n",
    "# plt.suptitle(f'Single Model Performance Across Train, Validation, and Test Sets', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "png_save_path = f\"plots/Performance_Comparison_5Models_Full_Comparison.png\"\n",
    "plt.savefig(png_save_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\n All performance comparison had been save in: {png_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c4990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting Full SHAP Analysis for RandomForest\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxj\\AppData\\Roaming\\Python\\Python39\\site-packages\\shap\\explainers\\_tree.py:253: FutureWarning: In the future, passing feature_perturbation='interventional' without providing a background dataset will raise an error. Please provide a background dataset to continue using the interventional approach or set feature_perturbation='auto' to automatically switch approaches.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> SHAP values calculated successfully.\n",
      "Plot saved to: plots/shap_summary_simple_randomforest.png\n",
      "-> 1/6 Plotted Simple Summary.\n",
      "Plot saved to: plots/feature_importance_bar_randomforest.png\n",
      "-> 2/6 Plotted Feature Importance Bar.\n",
      "Plot saved to: plots/shap_summary_with_bars_randomforest.png\n",
      "-> 3/6 Plotted Standard SHAP Summary.\n",
      "Plot saved to: plots/shap_dependence_plots_randomforest.png\n",
      "-> 4/6 Plotted Dependence Plots for 4 features.\n",
      "-> 5/6 Generated Log-Transformed Interpretation.\n",
      "Results saved to: output/SHAP_Analysis_randomforest_20251127_175119.xlsx\n",
      "-> 6/6 Saved results to Excel: output/SHAP_Analysis_randomforest_20251127_175119.xlsx\n",
      "============================================================\n",
      "Full SHAP Analysis for RandomForest COMPLETED.\n",
      "============================================================\n",
      "============================================================\n",
      "Starting Full SHAP Analysis for XGBoost\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxj\\AppData\\Roaming\\Python\\Python39\\site-packages\\shap\\explainers\\_tree.py:253: FutureWarning: In the future, passing feature_perturbation='interventional' without providing a background dataset will raise an error. Please provide a background dataset to continue using the interventional approach or set feature_perturbation='auto' to automatically switch approaches.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> SHAP values calculated successfully.\n",
      "Plot saved to: plots/shap_summary_simple_xgboost.png\n",
      "-> 1/6 Plotted Simple Summary.\n",
      "Plot saved to: plots/feature_importance_bar_xgboost.png\n",
      "-> 2/6 Plotted Feature Importance Bar.\n",
      "Plot saved to: plots/shap_summary_with_bars_xgboost.png\n",
      "-> 3/6 Plotted Standard SHAP Summary.\n",
      "Plot saved to: plots/shap_dependence_plots_xgboost.png\n",
      "-> 4/6 Plotted Dependence Plots for 4 features.\n",
      "-> 5/6 Generated Log-Transformed Interpretation.\n",
      "Results saved to: output/SHAP_Analysis_xgboost_20251127_175140.xlsx\n",
      "-> 6/6 Saved results to Excel: output/SHAP_Analysis_xgboost_20251127_175140.xlsx\n",
      "============================================================\n",
      "Full SHAP Analysis for XGBoost COMPLETED.\n",
      "============================================================\n",
      "============================================================\n",
      "Starting Full SHAP Analysis for LightGBM\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxj\\AppData\\Roaming\\Python\\Python39\\site-packages\\shap\\explainers\\_tree.py:253: FutureWarning: In the future, passing feature_perturbation='interventional' without providing a background dataset will raise an error. Please provide a background dataset to continue using the interventional approach or set feature_perturbation='auto' to automatically switch approaches.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> SHAP values calculated successfully.\n",
      "Plot saved to: plots/shap_summary_simple_lightgbm.png\n",
      "-> 1/6 Plotted Simple Summary.\n",
      "Plot saved to: plots/feature_importance_bar_lightgbm.png\n",
      "-> 2/6 Plotted Feature Importance Bar.\n",
      "Plot saved to: plots/shap_summary_with_bars_lightgbm.png\n",
      "-> 3/6 Plotted Standard SHAP Summary.\n",
      "Plot saved to: plots/shap_dependence_plots_lightgbm.png\n",
      "-> 4/6 Plotted Dependence Plots for 4 features.\n",
      "-> 5/6 Generated Log-Transformed Interpretation.\n",
      "Results saved to: output/SHAP_Analysis_lightgbm_20251127_175159.xlsx\n",
      "-> 6/6 Saved results to Excel: output/SHAP_Analysis_lightgbm_20251127_175159.xlsx\n",
      "============================================================\n",
      "Full SHAP Analysis for LightGBM COMPLETED.\n",
      "============================================================\n",
      "============================================================\n",
      "Starting Full SHAP Analysis for CatBoost\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lxj\\AppData\\Roaming\\Python\\Python39\\site-packages\\shap\\explainers\\_tree.py:253: FutureWarning: In the future, passing feature_perturbation='interventional' without providing a background dataset will raise an error. Please provide a background dataset to continue using the interventional approach or set feature_perturbation='auto' to automatically switch approaches.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> SHAP values calculated successfully.\n",
      "Plot saved to: plots/shap_summary_simple_catboost.png\n",
      "-> 1/6 Plotted Simple Summary.\n",
      "Plot saved to: plots/feature_importance_bar_catboost.png\n",
      "-> 2/6 Plotted Feature Importance Bar.\n",
      "Plot saved to: plots/shap_summary_with_bars_catboost.png\n",
      "-> 3/6 Plotted Standard SHAP Summary.\n",
      "Plot saved to: plots/shap_dependence_plots_catboost.png\n",
      "-> 4/6 Plotted Dependence Plots for 4 features.\n",
      "-> 5/6 Generated Log-Transformed Interpretation.\n",
      "Results saved to: output/SHAP_Analysis_catboost_20251127_175224.xlsx\n",
      "-> 6/6 Saved results to Excel: output/SHAP_Analysis_catboost_20251127_175224.xlsx\n",
      "============================================================\n",
      "Full SHAP Analysis for CatBoost COMPLETED.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from ML_shap import run_full_shap_analysis\n",
    "\n",
    "VARIABLE_MAPPING = {\n",
    "    \"somatic_y1\": \"Somatic Symptoms\",\n",
    "    \"BMI_T1_cat\": \"BMI Category\", \n",
    "    \"sleep_dura_T1_cat\": \"Sleep Duration\",\n",
    "    \"sleep_quali_T1\": \"Sleep Quality\",\n",
    "    \"insomnia_y1\": \"Baseline Insomnia\",\n",
    "    \n",
    "    \"life_satis_y1\": \"Life Satisfaction\",\n",
    "    \"ms_ses_y1\": \"Subjective SES\", \n",
    "    \"per_stress_y1\": \"Perceived Stress\", \n",
    "    \"ms_stress_y1\": \"Stress Mindset\",\n",
    "    \"depression_y1\": \"Depressive Symptoms\",\n",
    "    \"anxiety_y1\": \"Anxiety Symptoms\",\n",
    "    \n",
    "    \"ace\": \"Adverse Childhood Experiences\",\n",
    "    \n",
    "    \"loneliness_y1\": \"Loneliness\", \n",
    "    \"support_y1\": \"Social Support\",\n",
    "    \n",
    "    \"gender_T1\": \"Gender\",\n",
    "    \"age_T1\": \"Age\",\n",
    "    \"residence\": \"Residence\", \n",
    "    \"income\": \"Household Income\",\n",
    "    \"pocket_mon_T1\": \"Pocket Money\",\n",
    "    \"income_ineqCity_y1\": \"City Income Inequality\",\n",
    "    \"sss_now\": \"Subjective Social Status\",\n",
    "    \"marrige_par_bin\": \"Parental Marital Status\",\n",
    "    \"edu_pa\": \"Parental Education\",\n",
    "    \n",
    "    \"eat_unctl_y1\": \"Uncontrolled Eating\",\n",
    "    \"eat_emot_y1\": \"Emotional Eating\", \n",
    "    \"food_sweetdrink_T1\": \"Sweet Drink Consumption\",\n",
    "    \"food_takeout_T1\": \"Takeout Frequency\",\n",
    "    \n",
    "    \"IPAQ_T1_1_bin\": \"Vigorous Physical Activity\",\n",
    "    \"IPAQ_T1_3_bin\": \"Moderate Physical Activity\", \n",
    "    \"IPAQ_T1_5_bin\": \"Walking Activity\",\n",
    "    \n",
    "    \"screenT_weekday_T1\": \"Weekday Screen Time\",\n",
    "    \"screenT_weekend_T1\": \"Weekend Screen Time\",\n",
    "    \n",
    "    \"psmu_y1\": \"Problematic Social Media Use\",\n",
    "    \"media_BadMood_T1\": \"Media Use When Bad Mood\", \n",
    "    \"media_GoodMood_T1\": \"Media Use When Good Mood\",\n",
    "    \n",
    "    \"edu_self\": \"Self Educational Expectation\"\n",
    "}\n",
    "\n",
    "\n",
    "all_results = {\n",
    "    'RandomForest': res_rf,\n",
    "    'XGBoost': res_xgb,\n",
    "    'LightGBM': res_lgbm,\n",
    "    'CatBoost': res_cat\n",
    "}\n",
    "\n",
    "\n",
    "FLAG_SHOW = False \n",
    "FLAG_TITLE = False \n",
    "IS_LOG = False \n",
    "TOPN = 15\n",
    "\n",
    "\n",
    "for name, results in all_results.items():\n",
    "    run_full_shap_analysis(\n",
    "        model_name=name,\n",
    "        results=results,\n",
    "        df_model=df_model,         \n",
    "        selected_vars=selected_vars,\n",
    "        variable_mapping=VARIABLE_MAPPING,\n",
    "        is_log_transformed=IS_LOG,\n",
    "        top_n=TOPN,\n",
    "        flag_show=FLAG_SHOW,\n",
    "        flag_title=FLAG_TITLE\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
